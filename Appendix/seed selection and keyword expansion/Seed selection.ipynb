{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "global_glove_file = '../CI_Policy_Annotation/Flask/static/glove.6B/glove.6B.50d.txt'\n",
    "glove2word2vec(glove_input_file=global_glove_file, word2vec_output_file=\"gensim_glove_vectors.txt\")\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('fews-district-all.csv')\n",
    "countries = df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ethiopia', 'South Sudan', 'Central African Republic', 'Sudan',\n",
       "       'Democratic Republic of the Congo', 'Uganda', 'Kenya', 'Rwanda',\n",
       "       'Tanzania', 'Burundi', 'Mozambique', 'Malawi', 'Zambia', 'Somalia',\n",
       "       'Djibouti', 'Iilemi triangle', 'Chad', 'Abyei', 'Yemen', 'Haiti',\n",
       "       'Guatemala', 'Honduras', 'El Salvador', 'Afghanistan',\n",
       "       'Tajikistan', 'Angola', 'Zimbabwe', 'Madagascar', 'Congo',\n",
       "       'Guinea', 'Mali', 'Senegal', 'Mauritania', 'Burkina Faso',\n",
       "       'Nigeria', 'Niger', 'Cameroon', 'Sierra Leone', 'Liberia'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def bigram_sequence(text_lst):\n",
    "    result = [a for ls in text_lst for a in zip(ls.split(\" \")[:-1], ls.split(\" \")[1:]) if 'food' in a or 'hunger' in a]\n",
    "    return result\n",
    "\n",
    "def trigram_sequence(text_lst):\n",
    "    result = [a for ls in text_lst for a in zip(ls.split(\" \")[:-2], ls.split(\" \")[1:-1], ls.split(\" \")[2:]) if 'food' in a or 'hunger' in a]\n",
    "    return result\n",
    "\n",
    "def get_words(country):\n",
    "    words = Counter([])\n",
    "    for t in range(25):\n",
    "        # Post-processed Factiva avro files into csv\n",
    "        df = pd.read_csv(\"./templates-v3/{}/tmp{}.csv\".format(country, str(t).zfill(2)))\n",
    "        for r in df.iterrows():\n",
    "            unigrams = set(r[1]['body'].split())\n",
    "            bigrams = set(bigram_sequence(r[1]['body'].split('.')))\n",
    "            trigrams = set(trigram_sequence(r[1]['body'].split('.')))\n",
    "            words.update(unigrams)\n",
    "            words.update(bigrams)\n",
    "            words.update(trigrams)\n",
    "    return words\n",
    "\n",
    "all_words = Counter([])\n",
    "for country in countries:\n",
    "    all_words.update(get_words(country))\n",
    "select_df = pd.DataFrame()\n",
    "select_df['seed'] = list(all_words)\n",
    "select_df.to_csv('selected_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unigrams, bigrams and trigrams with word 'food' and 'hunger'\n",
    "seeds = pd.read_csv('selected_words.csv')\n",
    "keys = ['hunger crises', 'famine', 'food insecurity']\n",
    "seeds['distance'] = seeds['seed'].apply(lambda x: min([glove_model.wmdistance(x, k) for k in keys]))\n",
    "# including the 3 keys, retain just the top 100\n",
    "seeds.sort_values(by=['distance'])[:103].to_csv('seeds_with_distance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seeds['distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import Tree\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "#1211 causes from news and literature\n",
    "for country in countries:\n",
    "    tf_cause = {}\n",
    "    num_causes = 0\n",
    "    file_type = 'cause'\n",
    "    # these csv files are results from running the semantic frame parsing algorithm on news and literature\n",
    "    df = pd.read_csv('results/{}_seeded_{}_cluster.csv'.format(country, file_type), delimiter=',')\n",
    "    j = 1\n",
    "    cause_thr = 0\n",
    "    for cause, cause_sim in zip(df[df['{}_cluster'.format(file_type)] == i][file_type],\n",
    "                                df[df['{}_cluster'.format(file_type)] == i]['cause_similarity']):\n",
    "        num_causes += 1\n",
    "        tokenized_doc  = word_tokenize(cause)\n",
    "        tagged_sentences = pos_tag(tokenized_doc)\n",
    "        stem_cause = \" \".join([ps.stem(w) for w in cause.split(\" \")])\n",
    "        c_pre = ''\n",
    "        for tag in tagged_sentences:\n",
    "            c = ps.stem(tag[0])\n",
    "            t = tag[1]\n",
    "            if c in stemmed_stopwords or (not c.isalpha()) or c in black_list:\n",
    "                continue\n",
    "            if t.startswith('JJ'):\n",
    "                c_pre = c\n",
    "                continue\n",
    "            if c_pre:\n",
    "                c = c_pre + ' ' + c\n",
    "                c_pre = ''\n",
    "            if t.startswith('NN') and c_pre == '':\n",
    "                c_pre = c\n",
    "            tf_cause[c] = cause_sim[0]               \n",
    "    cause_df = pd.DataFrame.from_dict(tf_cause, orient='index', columns=['count'])\n",
    "    cause_df = cause_df.reset_index()\n",
    "    causes_df = pd.concat([causes_df, cause_df], axis=0)\n",
    "\n",
    "# expand \n",
    "for word, count in all_words.items():\n",
    "    if count <= 1000:\n",
    "        continue\n",
    "    for cause in causes_df['cause'].unique():\n",
    "        if glove_model.wmdistance(cause.split(), word.split()) < 6:\n",
    "            tf_cause = {'cause': word, 'dist': glove_model.wmdistance(cause.split(), word.split())}\n",
    "            cause_df = pd.DataFrame.from_dict(tf_cause)\n",
    "            cause_df = cause_df.reset_index()\n",
    "            causes_df = pd.concat([causes_df, cause_df])\n",
    "\n",
    "causes_df.to_csv('expanded_cluster_causes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get p-value of granger test for each of the variables with FEWS score\n",
    "sign_ind = [i for i,v in enumerate(list(causes_df['p_value']<0.01)) if v]\n",
    "causes = [causes_df.loc[i, 'cause'] for i in sign_ind]\n",
    "X_filtered = [X[i] for i in sign_ind]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
