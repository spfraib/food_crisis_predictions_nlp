{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_series = pd.read_csv('/home/ananth/Downloads/time_series_with_causes_zscore_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_variant_traditional_factors = ['ndvi_mean', 'ndvi_anom', 'rain_mean', 'rain_anom', 'et_mean', 'et_anom', \n",
    "                                    'acled_count', 'acled_fatalities', 'p_staple_food']\n",
    "t_invariant_traditional_factors = ['area', 'cropland_pct', 'pop', 'ruggedness_mean', 'pasture_pct']\n",
    "news_factors = [name for name in time_series.columns.values if '_0' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lagged(x, f, t):\n",
    "    admin_code = x['admin_code']\n",
    "    year = x['year']\n",
    "    month = x['month']\n",
    "    l_month = ((month-1-t)%12)+1\n",
    "    l_year = year\n",
    "    if month-t<=0:\n",
    "        l_year -= 1\n",
    "    ts=time_series[time_series['admin_code']==admin_code]\n",
    "    lagged_year_month = '{}_{}'.format(l_year, l_month)\n",
    "    if lagged_year_month in ts['year_month'].values:\n",
    "        ts = ts[ts['year_month']==lagged_year_month]\n",
    "        return ts[f].values[0]\n",
    "    else:\n",
    "        return x[f]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_time_lagged(features, start=3, end=9, diff=1, agg=True):\n",
    "    if agg:\n",
    "        levels = ['', '_province', '_country']\n",
    "    else:\n",
    "        levels = ['']\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f+suffix\n",
    "            for t in range(start,end,diff):\n",
    "                if '{}_{}'.format(f_s,t) in time_series:\n",
    "                    continue\n",
    "                time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admins = pd.read_csv('./famine-country-province-district-years-CS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(admins.country.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_names = time_series['admin_name'].unique()\n",
    "districts = admins['district'].unique()\n",
    "provinces = admins['province'].unique()\n",
    "countries = admins['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (len(admin_names), len(districts), len(provinces), len(countries))\n",
    "print (len(set(admin_names).difference(districts)))\n",
    "missing_admin_names = set(admin_names).difference(districts)\n",
    "print (len(missing_admin_names.difference(provinces)))\n",
    "missing_admin_names = missing_admin_names.difference(provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import editdistance\n",
    "from fuzzywuzzy import fuzz\n",
    "def find_matching(missing, names):\n",
    "    matching_districts = {}\n",
    "    for m in missing:\n",
    "        max_overlap = 0\n",
    "        nearest_d = None\n",
    "        for d in names:\n",
    "            d = str(d)\n",
    "            dist = fuzz.partial_ratio(m, d)\n",
    "            if dist > max_overlap:\n",
    "                max_overlap = dist\n",
    "                nearest_d = d\n",
    "        matching_districts[m] = nearest_d\n",
    "    return matching_districts\n",
    "\n",
    "\n",
    "matching = find_matching(missing_admin_names, districts)\n",
    "matching_p = find_matching(missing_admin_names, provinces)\n",
    "#manually verify matching and update\n",
    "for k in matching.keys():\n",
    "    print (k, matching[k], matching_p[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# after validating the matches, the names are logged in this csv file\n",
    "valid_matching = pd.read_csv('matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = valid_matching['missing'].unique()\n",
    "# matched = [bytes(m).decode(\"unicode_escape\") for  m in matched]\n",
    "missing_admin_names =  [m.decode(\"unicode_escape\").encode('ascii', 'backslashreplace') for m in missing_admin_names]\n",
    "print (len(missing_admin_names), len(matched))\n",
    "set(missing_admin_names).difference(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_province(x):\n",
    "    try:\n",
    "        if x in districts:\n",
    "            return admins[admins['district']==x]['province'].values[0]\n",
    "        elif x in provinces:\n",
    "            return x\n",
    "        elif x.decode(\"unicode_escape\").encode('ascii', 'backslashreplace') in matched:\n",
    "            x = x.decode(\"unicode_escape\").encode('ascii', 'backslashreplace')\n",
    "            v = valid_matching[valid_matching['missing']==x]\n",
    "            if v['match'].values[0]=='district':\n",
    "                x = v['district'].values[0]\n",
    "                return admins[admins['district']==x]['province'].values[0]\n",
    "            elif v['match'].values[0]=='province':\n",
    "                return v['province'].values[0]\n",
    "    except:\n",
    "        raise Exception(\"Province not found for: {}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_to_province = {}\n",
    "for a in admin_names:\n",
    "    try:\n",
    "        admin_to_province[a] = find_province(a)\n",
    "    except:\n",
    "        print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_series['province'] = time_series['admin_name'].apply(lambda x: admin_to_province[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_agg_factors(features, level='province'):\n",
    "    grouped_df = time_series.groupby(['year_month', level]).mean()\n",
    "    for f in features:\n",
    "        time_series['{}_{}'.format(f, level)] = time_series.apply(lambda x: grouped_df.ix[x['year_month'], x[level]][f], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_agg_factors(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_agg_factors(news_factors, level='country')\n",
    "add_agg_factors(t_variant_traditional_factors, level='province')\n",
    "add_agg_factors(t_variant_traditional_factors, level='country')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='province')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_series.to_csv('agg_province_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_series.to_csv('agg_province_country_all_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_time_lagged(t_variant_traditional_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_time_lagged(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_time_lagged(['fews_ipc'], end=21, diff=3, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_time_lagged(['fews_proj_near'], start=3, end=4, diff=1, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def diebold_mariano(preds, labels):\n",
    "    sq_error = [(p-l)**2 for p,l in zip(preds, labels)]\n",
    "    mean = np.mean(sq_error)\n",
    "    n = len(preds)\n",
    "    gammas = {}\n",
    "    m = max(n,int(math.ceil(np.cbrt(n))+2))\n",
    "    for k in range(m):\n",
    "        gammas[k] = 0\n",
    "        for i in range(k+1, n):\n",
    "            gammas[k] += (sq_error[i] - mean)*(sq_error[i-k] - mean)\n",
    "        gammas[k] = gammas[k]/n\n",
    "    sum_gamma = gammas[0]\n",
    "    for k in range(1, m):\n",
    "        sum_gamma += 2*gammas[k]\n",
    "    return np.sqrt(sum_gamma/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc, plot_precision_recall_curve\n",
    "\n",
    "test_splits = [\n",
    "    ((2010,7), (2011, 7)), \n",
    "    ((2011,7), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)), \n",
    "    ((2013,7), (2014, 7)), \n",
    "    ((2014,7), (2015, 7)), \n",
    "    ((2015,7), (2016, 7)), \n",
    "    ((2016,7), (2017, 7)), \n",
    "    ((2017,7), (2018, 7)),\n",
    "    ((2018,7), (2019, 7)), \n",
    "    ((2019,2), (2020, 2)),\n",
    "]\n",
    "train_splits = [\n",
    "    ((2009,7), (2010,4)),\n",
    "    ((2009,7), (2011,1)),\n",
    "    ((2009,7), (2011,10)),\n",
    "    ((2009,7), (2012,7)),\n",
    "    ((2009,7), (2013,7)),\n",
    "    ((2009,7), (2014,1)),\n",
    "    ((2009,7), (2015,1)),\n",
    "    ((2009,7), (2015,10)),\n",
    "    ((2009,7), (2016,10)),\n",
    "    ((2009,7), (2017,2))]\n",
    "dev_splits = [\n",
    "    ((2010,4), (2010, 7)),\n",
    "    ((2011,1), (2011, 7)),\n",
    "    ((2011,10), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)),\n",
    "    ((2013,4), (2014, 7)),\n",
    "    ((2014,1), (2015, 7)),\n",
    "    ((2015,1), (2016, 7)),\n",
    "    ((2015,10), (2017, 7)),\n",
    "    ((2016,10), (2018, 7)),\n",
    "    ((2017,2), (2019, 2)),\n",
    "]\n",
    "rf = RandomForestRegressor(max_features='auto', n_estimators=100, \n",
    "                             min_samples_split=0.5, min_impurity_decrease=0.001, random_state=0)\n",
    "ols = LinearRegression()\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "def get_agg_lagged_features(factors):\n",
    "    return ['{}_{}'.format(f, t) for f, t in zip(factors, range(3,9))] + \n",
    "           ['{}_province_{}'.format(f, t) for f, t in zip(factors, range(3,9))] +\n",
    "           ['{}_country_{}'.format(f, t) for f, t in zip(factors, range(3,9))]\n",
    "        \n",
    "\n",
    "features = {\n",
    "    'traditional': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ], \n",
    "    'news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ], \n",
    "    'traditional+news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert': time_series['fews_proj_near_3'],\n",
    "    'expert+traditional': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ],\n",
    "    'expert+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert+traditional+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ]\n",
    "}\n",
    "\n",
    "labels_df = time_series['fews_ipc']\n",
    "\n",
    "def get_time_split(df, start, end):\n",
    "    return df[df['year'] >= start[0] & df['month'] >= start[1] & df['year'] <= end[0] & df['month'] <= end[1]]\n",
    "\n",
    "for train, dev, test in zip(train_splits, dev_splits, test_splits):\n",
    "    for f, D in features.items():\n",
    "        X = get_time_split(D, train[0], train[1])\n",
    "        y = get_time_split(labels_df, test[0], test[1])\n",
    "        X_test = get_time_split(D, test[0], test[1])\n",
    "        for name, regr in zip(['RF', 'OLS', 'Lasso'], [rf, ols, lasso]):\n",
    "            regr.fit(X, y)\n",
    "            preds = regr.predict(X_test)\n",
    "            labels = get_time_split(labels_df, test[0], test[1])\n",
    "            rmse = mean_squared_error(labels, preds, squared=False)\n",
    "            stderr = diebold_mariano(preds, labels)\n",
    "            upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "            lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "            precision, recall, thresholds = precision_recall_curve(labels, preds)\n",
    "            auc_precision_recall = auc(recall, precision)\n",
    "            print (\"Method: {}, Split: {}, Features: {}, AUCPR: {}\".format(name, test, f, auc_precision_recall))\n",
    "            print (\"Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(name, test, f, rmse, lower_bound, upper_bound))\n",
    "            for country in time_series['country'].unique():\n",
    "                c_id = X_test[X_test['country']==country]\n",
    "                labels_c = labels[c_id]\n",
    "                preds_c = preds[c_id]\n",
    "                rmse = mean_squared_error(labels_c, preds_c, squared=False)\n",
    "                stderr = diebold_mariano(preds_c, labels_c)\n",
    "                upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "                lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "                print (\"Country: {}, Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(country, name, test, f, rmse, lower_bound, upper_bound))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
